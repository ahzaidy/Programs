{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3eBd1sJ8S2iaOUvTZFThW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Load word files with encoding\n",
        "\n",
        "def load_words(file_path, encoding=\"utf-8\"):\n",
        "    with urllib.request.urlopen(file_path) as response:\n",
        "        return [line.decode(encoding).strip() for line in response.readlines()]\n",
        "\n",
        "engl_words = load_words(\"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/english.txt\")\n",
        "grmn_words = load_words(\"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/german.txt\", encoding=\"latin1\")\n",
        "span_words = load_words(\"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/spanish.txt\")\n",
        "\n",
        "# Filter only 5-letter words\n",
        "def fltr_five_lttr_wrds(word_list):\n",
        "    return [word for word in word_list if len(word) == 5]\n",
        "\n",
        "engl_words = fltr_five_lttr_wrds(engl_words)\n",
        "grmn_words = fltr_five_lttr_wrds(grmn_words)\n",
        "span_words = fltr_five_lttr_wrds(span_words)\n",
        "\n",
        "# Assign labels: English = 0, German = 1, Spanish = 2\n",
        "engl_lbls = [0] * len(engl_words)\n",
        "grmn_lbls = [1] * len(grmn_words)\n",
        "span_lbls = [2] * len(span_words)\n",
        "\n",
        "# Combine datasets\n",
        "all_words = engl_words + grmn_words + span_words\n",
        "all_labels = engl_lbls + grmn_lbls + span_lbls\n",
        "\n",
        "# Convert words to numerical features using language-specific mappings\n",
        "def crt_chr_mapng(language):\n",
        "    if language == \"english\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    elif language == \"german\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzäöüß'\n",
        "    elif language == \"spanish\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzáéíóúüñ'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language\")\n",
        "\n",
        "    mapping = {}\n",
        "    for idx, char in enumerate(alphabet, start=1):\n",
        "        mapping[char] = idx\n",
        "    return mapping\n",
        "\n",
        "engl_mapng = crt_chr_mapng(\"english\")\n",
        "grmn_mapng = crt_chr_mapng(\"german\")\n",
        "span_mapng = crt_chr_mapng(\"spanish\")\n",
        "\n",
        "def word_to_features(word, language):\n",
        "    if language == 0:\n",
        "        mapping = engl_mapng\n",
        "    elif language == 1:\n",
        "        mapping = grmn_mapng\n",
        "    elif language == 2:\n",
        "        mapping = span_mapng\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language label\")\n",
        "\n",
        "    return [mapping.get(char.lower(), 0) for char in word]\n",
        "\n",
        "features = []\n",
        "for word, label in zip(all_words, all_labels):\n",
        "    features.append(word_to_features(word, label))\n",
        "\n",
        "# Create a DataFrame for features and labels\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = all_labels\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_length = data.shape[1] - 1\n",
        "data = data.apply(lambda row: row.fillna(0), axis=1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train and evaluate models\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"SVM\": SVC(kernel='linear', probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[model_name] = accuracy\n",
        "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Plot results with colorful bars\n",
        "colors = ['blue', 'green', 'orange']\n",
        "plt.barh(list(results.keys()), list(results.values()), color=colors)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "jV0BW535GNXV",
        "outputId": "51cbe639-f500-4e71-9060-ad57eb7f11a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d8f876bbe40f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Train and evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "file_url = \"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/english.txt\"\n",
        "\n",
        "with urllib.request.urlopen(file_url) as response:\n",
        "    lines = [line.decode(\"utf-8\").strip() for line in response.readlines()]\n",
        "\n",
        "print(f\"File has {len(lines)} lines\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVepwd07fKYA",
        "outputId": "bb200c68-6840-4bec-9962-2cbb76979666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File has 194433 lines\n"
          ]
        }
      ]
    }
  ]
}