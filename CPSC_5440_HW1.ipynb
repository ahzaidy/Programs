{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAZGwKrdIxfRsDzjHoTfEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#Author: Arif H. Zaidy                                                         #\n",
        "#Date: February 24, 2025                                                       #\n",
        "#Course: CPSC 5440                                                             #\n",
        "#Topic: Assignment 1                                                           #\n",
        "#Description:                                                                  #\n",
        "#This program classifies words into English, German, or Spanish using machine  #\n",
        "#learning models.                                                              #\n",
        "#It loads word lists, converts them into numerical features, and trains the    #\n",
        "#classifiers (KNN, SVM, MLP), after that it evaluates their accuracy.          #\n",
        "################################################################################\n",
        "\n",
        "# Import the python libraries\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "\n",
        "# Function to load word lists from a URL with specified encoding\n",
        "def load_words(file_path, encoding=\"utf-8\"):\n",
        "    with urllib.request.urlopen(file_path) as response:\n",
        "        return [line.decode(encoding).strip() for line in response.readlines()]\n",
        "\n",
        "# Load English, German, and Spanish word lists\n",
        "engl_words = load_words(\"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/english.txt\")\n",
        "grmn_words = load_words(\"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/german.txt\", encoding=\"latin1\")\n",
        "span_words = load_words(\"https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/spanish.txt\")\n",
        "\n",
        "# Function to filter only 5-letter words\n",
        "def fltr_five_lttr_wrds(word_list):\n",
        "    return [word for word in word_list if len(word) == 5]\n",
        "\n",
        "# Apply filtering to each language list\n",
        "engl_words = fltr_five_lttr_wrds(engl_words)\n",
        "grmn_words = fltr_five_lttr_wrds(grmn_words)\n",
        "span_words = fltr_five_lttr_wrds(span_words)\n",
        "\n",
        "# Assign numerical labels: English = 0, German = 1, Spanish = 2\n",
        "engl_lbls = [0] * len(engl_words)\n",
        "grmn_lbls = [1] * len(grmn_words)\n",
        "span_lbls = [2] * len(span_words)\n",
        "\n",
        "# Combine all words and labels into a single dataset\n",
        "all_words = engl_words + grmn_words + span_words\n",
        "all_labels = engl_lbls + grmn_lbls + span_lbls\n",
        "\n",
        "# Function to create character mapping for each language\n",
        "def crt_chr_mapng(language):\n",
        "    if language == \"english\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    elif language == \"german\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzäöüß'\n",
        "    elif language == \"spanish\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzáéíóúüñ'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language\")\n",
        "\n",
        "    # Assign a unique number to each character\n",
        "    mapping = {char: idx for idx, char in enumerate(alphabet, start=1)}\n",
        "    return mapping\n",
        "\n",
        "# Create character mappings for each language\n",
        "engl_mapng = crt_chr_mapng(\"english\")\n",
        "grmn_mapng = crt_chr_mapng(\"german\")\n",
        "span_mapng = crt_chr_mapng(\"spanish\")\n",
        "\n",
        "# Function to convert words into numerical features based on language mappings\n",
        "def word_to_features(word, language):\n",
        "    if language == 0:\n",
        "        mapping = engl_mapng\n",
        "    elif language == 1:\n",
        "        mapping = grmn_mapng\n",
        "    elif language == 2:\n",
        "        mapping = span_mapng\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language label\")\n",
        "\n",
        "    return [mapping.get(char.lower(), 0) for char in word]  # Convert characters to numbers\n",
        "\n",
        "# Convert all words into numerical feature vectors\n",
        "features = [word_to_features(word, label) for word, label in zip(all_words, all_labels)]\n",
        "\n",
        "# Create a DataFrame for features and labels\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = all_labels  # Add language labels as the target variable\n",
        "\n",
        "# Ensure all sequences have uniform length by padding missing values with zeros\n",
        "data = data.apply(lambda row: row.fillna(0), axis=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X = data.iloc[:, :-1]  # Features (word representations)\n",
        "y = data['label']       # Labels (language classification)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Define machine learning models for classification\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"SVM\": SVC(kernel='linear', probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)  # Train model\n",
        "    y_pred = model.predict(X_test)  # Predict on test set\n",
        "    accuracy = accuracy_score(y_test, y_pred)  # Compute accuracy\n",
        "    results[model_name] = accuracy\n",
        "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Plot accuracy comparison of models\n",
        "colors = ['blue', 'green', 'orange']\n",
        "plt.barh(list(results.keys()), list(results.values()), color=colors)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV0BW535GNXV",
        "outputId": "ca36b522-cb86-46bb-8367-84615b0a3e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 76.25%\n"
          ]
        }
      ]
    }
  ]
}