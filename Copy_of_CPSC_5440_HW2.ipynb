{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9TTw7ty8LBmljU+aop2Pq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/Copy_of_CPSC_5440_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KBCLx8uiVt0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "546315c7-f048-4b90-f488-3cc05ce0fe5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content//content/drive/My Drive/talos_output.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-54b15e38ae94>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Start Talos hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mt_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtalos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, multi_input, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights, save_models)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# start runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mscan_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/talos/scan/scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_prepare\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# initiate the progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/talos/scan/scan_prepare.py\u001b[0m in \u001b[0;36mscan_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscan_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# for the case where x_val or y_val is missing when other is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/talos/scan/scan_utils.py\u001b[0m in \u001b[0;36minitialize_log\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content//content/drive/My Drive/talos_output.csv'"
          ]
        }
      ],
      "source": [
        "import talos\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import time\n",
        "import io\n",
        "import base64\n",
        "import requests\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.service_account import Credentials\n",
        "\n",
        "# Path to the uploaded JSON key file\n",
        "json_keyfile_path = \"planar-door-449906-i1-eef65b127b3f.json\"  # Change this to your actual filename\n",
        "\n",
        "# Define the scope for Google Drive access\n",
        "SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "# Authenticate using the service account key\n",
        "creds = Credentials.from_service_account_file(json_keyfile_path, scopes=SCOPES)\n",
        "\n",
        "# Connect to Google Drive API\n",
        "drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
        "\n",
        "print(\"Successfully connected to Google Drive!\")\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "with open('/content/drive/My Drive/train', 'rb') as file:\n",
        "    train_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "with open('/content/drive/My Drive/test', 'rb') as file:\n",
        "    test_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "X_train = train_dict[b'data']\n",
        "y_train = train_dict[b'coarse_labels']\n",
        "\n",
        "X_test = test_dict[b'data']\n",
        "y_test = test_dict[b'coarse_labels']\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
        "\n",
        "# Define parameter dictionary for Talos\n",
        "p = {\n",
        "    'units': [120, 240],\n",
        "    'hidden_activations': ['relu', 'sigmoid'],\n",
        "    'activation': ['softmax', 'sigmoid'],\n",
        "    'loss': ['mse', 'categorical_crossentropy'],\n",
        "    'optimizer': ['adam', 'adagrad'],\n",
        "    'batch_size': [1000, 2000]\n",
        "}\n",
        "\n",
        "# Define the model function for Talos\n",
        "def my_model(X_train, y_train, X_val, y_val, params):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=params['units'], activation=params['hidden_activations'], input_dim=X_train.shape[1]))\n",
        "\n",
        "    for _ in range(4):  # Adding 4 hidden layers\n",
        "        model.add(Dense(units=params['units'], activation=params['hidden_activations']))\n",
        "\n",
        "    model.add(Dense(units=100, activation=params['activation']))  # Output layer\n",
        "\n",
        "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
        "\n",
        "    out = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                        batch_size=params['batch_size'], epochs=50, verbose=0)\n",
        "\n",
        "    return out, model\n",
        "csv_filename = \"drive/My Drive/talos_output.csv\"\n",
        "\n",
        "# Start Talos hyperparameter tuning\n",
        "start_time = time.time()\n",
        "t_object = talos.Scan(x=X_train, y=y_train, params=p, model=my_model, x_val=X_test, y_val=y_test, round_limit=5, experiment_name=csv_filename)\n",
        "\n",
        "df = t_object.data\n",
        "\n",
        "# Save results as CSV locally\n",
        "\n",
        "# df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Find the best performing hyperparameter set based on training accuracy\n",
        "best_accuracy = df['accuracy'].max() * 100  # Convert to percentage\n",
        "best_accuracy_rounded = round(best_accuracy)\n",
        "\n",
        "# Calculate point deduction\n",
        "deduction = max(0, 20 - best_accuracy_rounded)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nBest Training Accuracy: {best_accuracy:.2f}% (Rounded: {best_accuracy_rounded}%)\")\n",
        "print(f\"Point Deduction: {deduction} points\")\n",
        "print(f\"Total Execution Time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# The Talos CSV output is stored in the variable `talos_output_csv`\n"
      ]
    }
  ]
}