{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJlUV/uGlApTnkNlH+AzCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JxZfD2h_3bq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Set dataset paths\n",
        "train_dir = \"/content/drive/My Drive/train1/\"\n",
        "test_dir = \"/content/drive/My Drive/test1/\"\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images(directory, size=(56, 56)):\n",
        "    images = []\n",
        "    filenames = os.listdir(directory)\n",
        "    for file in filenames:\n",
        "        img = plt.imread(os.path.join(directory, file))  # Load image as np.array\n",
        "        img = np.resize(img, (*size, 3)) / 255.0  # Normalize and resize\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images\n",
        "x_train = load_images(train_dir)\n",
        "x_test = load_images(test_dir)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "\n",
        "# Add noise to training data\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * torch.randn_like(x_train)\n",
        "x_test_noisy = x_test + noise_factor * torch.randn_like(x_test)\n",
        "x_train_noisy = torch.clamp(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = torch.clamp(x_test_noisy, 0., 1.)\n",
        "\n",
        "# Define Autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(32, 3, kernel_size=3, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Autoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x_train_noisy.to(device))\n",
        "    loss = criterion(outputs, x_train.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"/content/drive/My Drive/image_upscaler.pth\")\n",
        "\n",
        "# Evaluate model\n",
        "model.eval()\n",
        "reconstructed = model(x_test_noisy.to(device)).cpu().detach().numpy()\n",
        "\n",
        "# Compute MSE and SSIM\n",
        "mse_values = []\n",
        "ssim_values = []\n",
        "num_images = 50  # Reduced for demonstration purposes\n",
        "\n",
        "fig, axes = plt.subplots(10, 3, figsize=(10, 20))\n",
        "for i in range(num_images):\n",
        "    original = x_test[i].permute(1, 2, 0).numpy()\n",
        "    noisy = x_test_noisy[i].permute(1, 2, 0).numpy()\n",
        "    recon = reconstructed[i].transpose(1, 2, 0)\n",
        "\n",
        "    mse = mean_squared_error(original.flatten(), recon.flatten())\n",
        "    mse_values.append(mse)\n",
        "    ssim_index = ssim(original, recon, data_range=1.0, channel_axis=-1)\n",
        "    ssim_values.append(ssim_index)\n",
        "\n",
        "    axes[i, 0].imshow(original)\n",
        "    axes[i, 0].set_title(\"Original\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    axes[i, 1].imshow(noisy)\n",
        "    axes[i, 1].set_title(\"Noisy\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "    axes[i, 2].imshow(recon)\n",
        "    axes[i, 2].set_title(f\"Reconstructed\\nMSE: {mse:.4f}\\nSSIM: {ssim_index:.4f}\")\n",
        "    axes[i, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print average MSE and SSIM\n",
        "print(f\"Average MSE: {np.mean(mse_values):.4f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_values):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skimage"
      ],
      "metadata": {
        "id": "esn71r1whYKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}