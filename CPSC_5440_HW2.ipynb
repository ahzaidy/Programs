{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjPZR94YiIJQ5DvBqniSJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8KBCLx8uiVt0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "9938a17b-6461-49ef-ebd4-4a2cadc82849"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'talos'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eb3ccc1edcfa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtalos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'talos'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import talos\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import time\n",
        "import io\n",
        "import base64\n",
        "import requests\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "with open('/content/drive/My Drive/train', 'rb') as file:\n",
        "    train_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "with open('/content/drive/My Drive/test', 'rb') as file:\n",
        "    test_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "X_train = train_dict[b'data']\n",
        "y_train = train_dict[b'coarse_labels']\n",
        "\n",
        "X_test = test_dict[b'data']\n",
        "y_test = test_dict[b'coarse_labels']\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
        "\n",
        "# Define parameter dictionary for Talos\n",
        "p = {\n",
        "    'units': [120, 240],\n",
        "    'hidden_activations': ['relu', 'sigmoid'],\n",
        "    'activation': ['softmax', 'sigmoid'],\n",
        "    'loss': ['mse', 'categorical_crossentropy'],\n",
        "    'optimizer': ['adam', 'adagrad'],\n",
        "    'batch_size': [1000, 2000]\n",
        "}\n",
        "\n",
        "# Define the model function for Talos\n",
        "def my_model(X_train, y_train, X_val, y_val, params):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=params['units'], activation=params['hidden_activations'], input_dim=X_train.shape[1]))\n",
        "\n",
        "    for _ in range(4):  # Adding 4 hidden layers\n",
        "        model.add(Dense(units=params['units'], activation=params['hidden_activations']))\n",
        "\n",
        "    model.add(Dense(units=100, activation=params['activation']))  # Output layer\n",
        "\n",
        "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
        "\n",
        "    out = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                        batch_size=params['batch_size'], epochs=100, verbose=0)\n",
        "\n",
        "    return out, model\n",
        "csv_filename = \"drive/My Drive/talos_output\"\n",
        "\n",
        "# Start Talos hyperparameter tuning\n",
        "start_time = time.time()\n",
        "t_object = talos.Scan(x=X_train, y=y_train, params=p, model=my_model, x_val=X_test, y_val=y_test, round_limit=64, experiment_name=csv_filename)\n",
        "\n",
        "df = t_object.data\n",
        "\n",
        "# Find the best performing hyperparameter set based on training accuracy\n",
        "best_accuracy = df['accuracy'].max() * 100  # Convert to percentage\n",
        "best_accuracy_rounded = round(best_accuracy)\n",
        "\n",
        "# Calculate point deduction\n",
        "deduction = max(0, 20 - best_accuracy_rounded)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nBest Training Accuracy: {best_accuracy:.2f}% (Rounded: {best_accuracy_rounded}%)\")\n",
        "print(f\"Point Deduction: {deduction} points\")\n",
        "print(f\"Total Execution Time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# The Talos CSV output is stored in the variable `talos_output_csv`\n"
      ]
    }
  ]
}