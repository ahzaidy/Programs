{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7c7pZafQUChG/TiGyZz4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/Copy_of_CPSC_5450_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Load word files with encoding\n",
        "\n",
        "def load_words(file_path, encoding=\"utf-8\"):\n",
        "    with open(file_path, 'r', encoding=encoding) as file:\n",
        "        return [line.strip() for line in file.readlines()]\n",
        "\n",
        "english_words = load_words('/content/drive/My Drive/english.txt')\n",
        "german_words = load_words('/content/drive/My Drive/german.txt', encoding=\"latin1\")\n",
        "spanish_words = load_words('/content/drive/My Drive/spanish.txt')\n",
        "\n",
        "# Filter only 5-letter words\n",
        "def filter_five_letter_words(word_list):\n",
        "    return [word for word in word_list if len(word) == 5]\n",
        "\n",
        "english_words = filter_five_letter_words(english_words)\n",
        "german_words = filter_five_letter_words(german_words)\n",
        "spanish_words = filter_five_letter_words(spanish_words)\n",
        "\n",
        "# Assign labels: English = 0, German = 1, Spanish = 2\n",
        "english_labels = [0] * len(english_words)\n",
        "german_labels = [1] * len(german_words)\n",
        "spanish_labels = [2] * len(spanish_words)\n",
        "\n",
        "# Combine datasets\n",
        "all_words = english_words + german_words + spanish_words\n",
        "all_labels = english_labels + german_labels + spanish_labels\n",
        "\n",
        "# Convert words to numerical features using language-specific mappings\n",
        "def create_char_mapping(language):\n",
        "    if language == \"english\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    elif language == \"german\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzäöüß'\n",
        "    elif language == \"spanish\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzáéíóúüñ'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language\")\n",
        "\n",
        "    mapping = {}\n",
        "    for idx, char in enumerate(alphabet, start=1):\n",
        "        mapping[char] = idx\n",
        "    return mapping\n",
        "\n",
        "english_mapping = create_char_mapping(\"english\")\n",
        "german_mapping = create_char_mapping(\"german\")\n",
        "spanish_mapping = create_char_mapping(\"spanish\")\n",
        "\n",
        "def word_to_features(word, language):\n",
        "    if language == 0:\n",
        "        mapping = english_mapping\n",
        "    elif language == 1:\n",
        "        mapping = german_mapping\n",
        "    elif language == 2:\n",
        "        mapping = spanish_mapping\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language label\")\n",
        "\n",
        "    return [mapping.get(char.lower(), 0) for char in word]\n",
        "\n",
        "features = []\n",
        "for word, label in zip(all_words, all_labels):\n",
        "    features.append(word_to_features(word, label))\n",
        "\n",
        "# Create a DataFrame for features and labels\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = all_labels\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_length = data.shape[1] - 1\n",
        "data = data.apply(lambda row: row.fillna(0), axis=1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate models\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"SVM\": SVC(kernel='linear', probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[model_name] = accuracy\n",
        "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Plot results\n",
        "plt.barh(list(results.keys()), list(results.values()))\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV0BW535GNXV",
        "outputId": "233b9e7b-04db-4562-e4e3-36eda1c16ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "KNN Accuracy: 75.01%\n"
          ]
        }
      ]
    }
  ]
}