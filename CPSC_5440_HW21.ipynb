{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZv5fvcvBzrUWrHDdKV0/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "xGMaKqWQ7VBm",
        "outputId": "9310b3a9-6593-416e-fb55-b8250fcf69d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-2-3e4dcbfb5df6>, line 123)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-3e4dcbfb5df6>\"\u001b[0;36m, line \u001b[0;32m123\u001b[0m\n\u001b[0;31m    'epochs': epoch + 1\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "from torchvision import datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Load CIFAR-100 dataset from Google Drive\n",
        "with open('/content/drive/My Drive/train', 'rb') as file:\n",
        "    train_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "with open('/content/drive/My Drive/test', 'rb') as file:\n",
        "    test_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "# Extract data and labels\n",
        "train_data = torch.tensor(train_dict[b'data'], dtype=torch.float32).reshape(-1, 3, 32, 32) / 255.0\n",
        "train_labels = torch.tensor(train_dict[b'fine_labels'], dtype=torch.long)\n",
        "test_data = torch.tensor(test_dict[b'data'], dtype=torch.float32).reshape(-1, 3, 32, 32) / 255.0\n",
        "test_labels = torch.tensor(test_dict[b'fine_labels'], dtype=torch.long)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "train_data = torch.stack([transform(image) for image in train_data])\n",
        "test_data = torch.stack([transform(image) for image in test_data])\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TensorDataset(train_data, train_labels)\n",
        "test_dataset = TensorDataset(test_data, test_labels)\n",
        "\n",
        "# Define the CNN model (ResNet18)\n",
        "class CIFAR100ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR100ResNet, self).__init__()\n",
        "        self.model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, 100)  # CIFAR-100 has 100 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cpu\")\n",
        "model = CIFAR100ResNet().to(device)\n",
        "\n",
        "# Set hyperparameters\n",
        "config = {\n",
        "    'batch_size': 128,\n",
        "    'lr': 0.1,\n",
        "    'epochs': 200,\n",
        "    'weight_decay': 1e-4\n",
        "}\n",
        "\n",
        "# Prepare data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.2)\n",
        "\n",
        "# Training function\n",
        "def train_cifar100(model, train_loader, test_loader, optimizer, criterion, scheduler, device, epochs=200):\n",
        "    best_accuracy = 0.0\n",
        "    best_config = {}\n",
        "    history = {'epoch': [], 'accuracy': []}\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()  # Update learning rate\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(test_loader)\n",
        "        val_accuracy = correct / total\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['accuracy'].append(val_accuracy)\n",
        "        print(f'Epoch {epoch+1}, Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Update best accuracy and config\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            best_config = {\n",
        "                'batch_size': config['batch_size'],\n",
        "                'lr': config['lr'],\n",
        "                'epochs': epoch + 1,\n",
        "                'weight_decay': config['weight_decay']\n",
        "            }\n",
        "\n",
        "    return history, best_accuracy, best_config\n",
        "\n",
        "# Train model\n",
        "history, best_accuracy, best_config = train_cifar100(\n",
        "    model, train_loader, test_loader, optimizer, criterion, scheduler, device, epochs=config['epochs']\n",
        ")\n",
        "\n",
        "# Plot results\n",
        "df = pd.DataFrame(history)\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(data=df, x='epoch', y='accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('CIFAR-100 Training Results')\n",
        "plt.grid()\n",
        "plt.savefig(\"/content/drive/My Drive/cifar100_training_plot.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Display best accuracy and corresponding hyperparameters\n",
        "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
        "print('Best Hyperparameters:')\n",
        "for key, value in best_config.items():\n",
        "    print(f'  {key}: {value}')"
      ]
    }
  ]
}