{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ34nLy241l8h4ao1sOK/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JxZfD2h_3bq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set dataset paths\n",
        "train_dir = \"/content/drive/My Drive/train/\"\n",
        "test_dir = \"/content/drive/My Drive/test1/\"\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images(directory, size=(28, 28)):\n",
        "    images = []\n",
        "    filenames = os.listdir(directory)\n",
        "    for file in filenames:\n",
        "        img = load_img(os.path.join(directory, file), target_size=size)\n",
        "        img = img_to_array(img) / 255.0  # Normalize\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load and preprocess images\n",
        "x_train = load_images(train_dir)\n",
        "x_test = load_images(test_dir)\n",
        "\n",
        "# Reshape for model compatibility\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 3))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 3))\n",
        "\n",
        "# Add noise to training data\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_img = Input(shape=(28, 28, 3))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Compile model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test))\n",
        "\n",
        "# Save model\n",
        "autoencoder.save(\"/content/drive/My Drive/image_upscaler.h5\")\n",
        "\n",
        "# Load trained model and visualize output\n",
        "num_images = 10  # Reduced for demonstration purposes\n",
        "test_samples = x_test_noisy[:num_images]\n",
        "reconstructed = autoencoder.predict(test_samples)\n",
        "\n",
        "# Initialize lists to store MSE and SSIM values\n",
        "mse_values = []\n",
        "ssim_values = []\n",
        "\n",
        "fig, axes = plt.subplots(num_images, 3, figsize=(10, num_images * 2))\n",
        "for i in range(num_images):\n",
        "    # Original image\n",
        "    original = x_test[i]\n",
        "    # Noisy input\n",
        "    noisy = test_samples[i]\n",
        "    # Reconstructed image\n",
        "    recon = reconstructed[i]\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(original.flatten(), recon.flatten())\n",
        "    mse_values.append(mse)\n",
        "\n",
        "    # Calculate SSIM\n",
        "    ssim_index = ssim(original, recon, multichannel=True)\n",
        "    ssim_values.append(ssim_index)\n",
        "\n",
        "    # Display images\n",
        "    axes[i, 0].imshow(original)\n",
        "    axes[i, 0].set_title(\"Original\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    axes[i, 1].imshow(noisy)\n",
        "    axes[i, 1].set_title(\"Noisy\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "    axes[i, 2].imshow(recon)\n",
        "    axes[i, 2].set_title(f\"Reconstructed\\nMSE: {mse:.4f}\\nSSIM: {ssim_index:.4f}\")\n",
        "    axes[i, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print average MSE and SSIM\n",
        "print(f\"Average MSE: {np.mean(mse_values):.4f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_values):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store MSE and SSIM values\n",
        "mse_values = []\n",
        "ssim_values = []\n",
        "\n",
        "fig, axes = plt.subplots(num_images, 3, figsize=(10, num_images * 2))\n",
        "for i in range(num_images):\n",
        "    # Original image\n",
        "    original = x_test[i]\n",
        "    # Noisy input\n",
        "    noisy = test_samples[i]\n",
        "    # Reconstructed image\n",
        "    recon = reconstructed[i]\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(original.flatten(), recon.flatten())\n",
        "    mse_values.append(mse)\n",
        "\n",
        "    # Calculate SSIM\n",
        "    ssim_index = ssim(original, recon, multichannel=True)\n",
        "    ssim_values.append(ssim_index)\n",
        "\n",
        "    # Display images\n",
        "    axes[i, 0].imshow(original)\n",
        "    axes[i, 0].set_title(\"Original\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    axes[i, 1].imshow(noisy)\n",
        "    axes[i, 1].set_title(\"Noisy\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "    axes[i, 2].imshow(recon)\n",
        "    axes[i, 2].set_title(f\"Reconstructed\\nMSE: {mse:.4f}\\nSSIM: {ssim_index:.4f}\")\n",
        "    axes[i, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print average MSE and SSIM\n",
        "print(f\"Average MSE: {np.mean(mse_values):.4f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_values):.4f}\")"
      ],
      "metadata": {
        "id": "XJmrEtz6hzP6",
        "outputId": "a54b9230-683d-4ac4-bf47-83969a83a89d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skimage"
      ],
      "metadata": {
        "id": "esn71r1whYKc",
        "outputId": "d596d0e9-1b93-4add-fecd-b9fbad8cad47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skimage\n",
            "  Downloading skimage-0.0.tar.gz (757 bytes)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    }
  ]
}