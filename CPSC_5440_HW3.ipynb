{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNna8T+TBYs5nhxXfci5/Wm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JxZfD2h_3bq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Set dataset paths\n",
        "train_dir = \"train\"\n",
        "test_dir = \"test\"\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images(directory, size=(28, 28)):\n",
        "    images = []\n",
        "    filenames = os.listdir(directory)\n",
        "    for file in filenames:\n",
        "        img = load_img(os.path.join(directory, file), target_size=size)\n",
        "        img = img_to_array(img) / 255.0  # Normalize\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load and preprocess images\n",
        "x_train = load_images(train_dir)\n",
        "x_test = load_images(test_dir)\n",
        "\n",
        "# Reshape for model compatibility\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 3))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 3))\n",
        "\n",
        "# Add noise to training data\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_img = Input(shape=(28, 28, 3))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Compile model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test))\n",
        "\n",
        "# Save model\n",
        "autoencoder.save(\"image_upscaler.h5\")\n",
        "\n",
        "# Load trained model and visualize output\n",
        "num_images = 50\n",
        "test_samples = x_test_noisy[:num_images]\n",
        "reconstructed = autoencoder.predict(test_samples)\n",
        "\n",
        "fig, axes = plt.subplots(num_images, 3, figsize=(10, num_images * 2))\n",
        "for i in range(num_images):\n",
        "    axes[i, 0].imshow(x_test[i])\n",
        "    axes[i, 0].set_title(\"Original\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    axes[i, 1].imshow(test_samples[i])\n",
        "    axes[i, 1].set_title(\"Noisy\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "    axes[i, 2].imshow(reconstructed[i])\n",
        "    axes[i, 2].set_title(\"Reconstructed\")\n",
        "    axes[i, 2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}