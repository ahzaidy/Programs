{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN23aWH4Dyad8Bla2S9VYy7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5450_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load word files\n",
        "def load_words(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip() for line in file.readlines()]\n",
        "\n",
        "english_words = load_words('https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/english.txt')\n",
        "german_words = load_words('https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/german.txt')\n",
        "spanish_words = load_words('https://raw.githubusercontent.com/ahzaidy/Programs/refs/heads/main/spanish.txt')\n",
        "\n",
        "# Filter only 5-letter words\n",
        "def filter_five_letter_words(word_list):\n",
        "    return [word for word in word_list if len(word) == 5]\n",
        "\n",
        "english_words = filter_five_letter_words(english_words)\n",
        "german_words = filter_five_letter_words(german_words)\n",
        "spanish_words = filter_five_letter_words(spanish_words)\n",
        "\n",
        "# Assign labels: English = 0, German = 1, Spanish = 2\n",
        "english_labels = [0] * len(english_words)\n",
        "german_labels = [1] * len(german_words)\n",
        "spanish_labels = [2] * len(spanish_words)\n",
        "\n",
        "# Combine datasets\n",
        "all_words = english_words + german_words + spanish_words\n",
        "all_labels = english_labels + german_labels + spanish_labels\n",
        "\n",
        "# Convert words to numerical features using language-specific mappings\n",
        "def create_char_mapping(language):\n",
        "    if language == \"english\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    elif language == \"german\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzäöüß'\n",
        "    elif language == \"spanish\":\n",
        "        alphabet = 'abcdefghijklmnopqrstuvwxyzáéíóúüñ'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language\")\n",
        "\n",
        "    mapping = {}\n",
        "    for idx, char in enumerate(alphabet, start=1):\n",
        "        mapping[char] = idx\n",
        "    return mapping\n",
        "\n",
        "english_mapping = create_char_mapping(\"english\")\n",
        "german_mapping = create_char_mapping(\"german\")\n",
        "spanish_mapping = create_char_mapping(\"spanish\")\n",
        "\n",
        "def word_to_features(word, language):\n",
        "    if language == 0:\n",
        "        mapping = english_mapping\n",
        "    elif language == 1:\n",
        "        mapping = german_mapping\n",
        "    elif language == 2:\n",
        "        mapping = spanish_mapping\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported language label\")\n",
        "\n",
        "    return [mapping.get(char.lower(), 0) for char in word]\n",
        "\n",
        "features = []\n",
        "for word, label in zip(all_words, all_labels):\n",
        "    features.append(word_to_features(word, label))\n",
        "\n",
        "features = np.array(features)\n",
        "labels = np.array(all_labels)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_length = max(len(f) for f in features)\n",
        "features = np.array([np.pad(f, (0, max_length - len(f)), constant_values=0) for f in features])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate models\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"SVM\": SVC(kernel='linear', probability=True),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[model_name] = accuracy\n",
        "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Plot results\n",
        "plt.bar(results.keys(), results.values())\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pEEabsiXDlZq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}