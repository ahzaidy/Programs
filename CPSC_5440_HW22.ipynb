{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq4w47svGPn7V0gDnC5ldW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahzaidy/Programs/blob/main/CPSC_5440_HW22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "7iuZVNMWq96F",
        "outputId": "fc3600f1-3281-4e59-bbe8-2bebe37198a6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 14 (<ipython-input-1-2dfd451f4191>, line 18)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2dfd451f4191>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    drive.mount(\"/content/drive\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 14\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import talos as ta\n",
        "from google.colab import drive\n",
        "# Load CIFAR-100 dataset\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "def load_data():\n",
        "\n",
        "# Load CIFAR-100 dataset from Google Drive\n",
        "    with open('/content/drive/My Drive/train', 'rb') as file:\n",
        "        train_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "    with open('/content/drive/My Drive/test', 'rb') as file:\n",
        "        test_dict = pickle.load(file, encoding='bytes')\n",
        "\n",
        "    X_train = train_dict[b'data']\n",
        "    y_train = train_dict[b'coarse_labels']\n",
        "    X_test = test_dict[b'data']\n",
        "    y_test = test_dict[b'coarse_labels']\n",
        "\n",
        "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
        "    y_train = enc.fit_transform(np.array(y_train).reshape(-1, 1))\n",
        "    y_test = enc.transform(np.array(y_test).reshape(-1, 1))\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# Define the neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, hidden_activation, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        activation_fn = nn.ReLU() if hidden_activation == 'relu' else nn.Sigmoid()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_units),\n",
        "            activation_fn,\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            activation_fn,\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            activation_fn,\n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            activation_fn,\n",
        "            nn.Linear(hidden_units, output_size),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Train function\n",
        "def train_model(X_train, y_train, X_test, y_test, params):\n",
        "    model = NeuralNet(3072, params['units'], params['hidden_activations'], 100)\n",
        "    criterion = nn.CrossEntropyLoss() if params['loss'] == 'categorical_crossentropy' else nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters()) if params['optimizer'] == 'adam' else optim.Adagrad(model.parameters())\n",
        "\n",
        "    train_loader = data.DataLoader(data.TensorDataset(X_train, y_train), batch_size=params['batch_size'], shuffle=True)\n",
        "    test_loader = data.DataLoader(data.TensorDataset(X_test, y_test), batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "    history = {'epoch': [], 'accuracy': []}\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(200):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                outputs = model(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                _, labels = torch.max(batch_y, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        accuracy = correct / total\n",
        "        history['epoch'].append(epoch)\n",
        "        history['accuracy'].append(accuracy)\n",
        "\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "\n",
        "    print(f\"Best Accuracy: {best_acc * 100:.2f}%\")\n",
        "\n",
        "    df = pd.DataFrame(history)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.lineplot(data=df, x='epoch', y='accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.title('CIFAR-100 Training Results')\n",
        "    plt.grid()\n",
        "    plt.savefig(\"/content/drive/My Drive/cifar100_training_plot.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define Talos parameter dictionary\n",
        "p = {\n",
        "    'units': [120, 240],\n",
        "    'hidden_activations': ['relu', 'sigmoid'],\n",
        "    'loss': ['mse', 'categorical_crossentropy'],\n",
        "    'optimizer': ['adam', 'adagrad'],\n",
        "    'batch_size': [1000, 2000]\n",
        "}\n",
        "\n",
        "# Load data\n",
        "X_train, y_train, X_test, y_test = load_data()\n",
        "\n",
        "# Run Talos scan\n",
        "ta.Scan(x=X_train.numpy(),\n",
        "        y=y_train.numpy(),\n",
        "        model=train_model,\n",
        "        params=p,\n",
        "        experiment_name='cifar100_talos')"
      ]
    }
  ]
}